{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version 4.4.0\n",
      "Numpy version 1.17.2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "print(\"OpenCV version\",cv2.__version__)\n",
    "print(\"Numpy version\",np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images(percent_split):\n",
    "    # initiate img types and path\n",
    "    img_types = [\"C\", \"L\", \"R\"]\n",
    "    dataset_size = 0\n",
    "    \n",
    "    _, _, fake_data_count = next(os.walk(\"./fake\"))\n",
    "    dataset_size += len(fake_data_count) - 1\n",
    "    fake_data_count = (len(fake_data_count) - 1)// 3\n",
    "    \n",
    "    _, _, real_data_count = next(os.walk(\"./real\"))\n",
    "    dataset_size += len(real_data_count) - 1\n",
    "    real_data_count = (len(real_data_count) - 1) // 3\n",
    "\n",
    "    real_imgs = [\n",
    "        [cv2.imread(f\"./real/{i}{t}r.jpg\") for t in img_types]\n",
    "        for i in range(1, real_data_count + 1)\n",
    "    ]\n",
    "    fake_imgs = [\n",
    "        [cv2.imread(f\"./fake/{i}{t}f.jpg\") for t in img_types]\n",
    "        for i in range(1, fake_data_count + 1)\n",
    "    ]\n",
    "\n",
    "    real_split_idx = int(real_data_count*percent_split)\n",
    "    fake_split_idx = int(fake_data_count*percent_split)\n",
    "    \n",
    "    real_test_count = len(real_imgs[real_split_idx:])\n",
    "    fake_test_count = len(fake_imgs[fake_split_idx:])\n",
    "    \n",
    "    test_imgs = real_imgs[real_split_idx:]+fake_imgs[fake_split_idx:]\n",
    "    real_imgs = real_imgs[:real_split_idx]\n",
    "    fake_imgs = fake_imgs[:fake_split_idx]\n",
    "    \n",
    "    return real_imgs, fake_imgs, test_imgs, real_test_count, fake_test_count, dataset_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascade Face Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceFinder:\n",
    "    def __init__(self, path) -> None:\n",
    "\n",
    "        # load frontal face detector files\n",
    "        cv2.samples.addSamplesDataSearchPath(path)\n",
    "        front_face_cascade_name = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "        # load frontal alt detector files\n",
    "        cv2.samples.addSamplesDataSearchPath(path)\n",
    "        alt_face_cascade_name = \"haarcascade_frontalface_alt.xml\"\n",
    "\n",
    "        # load frontal alt2 detector files\n",
    "        cv2.samples.addSamplesDataSearchPath(path)\n",
    "        alt2_face_cascade_name = \"haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "        # load frontal profile detector files\n",
    "        cv2.samples.addSamplesDataSearchPath(path)\n",
    "        profile_face_cascade_name = \"haarcascade_profileface.xml\"\n",
    "\n",
    "        # create and load the frontal face cascade\n",
    "        self.frontal_face_cascade = cv2.CascadeClassifier()\n",
    "        if not self.frontal_face_cascade.load(\n",
    "            cv2.samples.findFile(front_face_cascade_name)\n",
    "        ):\n",
    "            print(\"--(!)Error loading frontal face cascade\")\n",
    "            exit(0)\n",
    "\n",
    "        # create and load the alt face cascade\n",
    "        self.alt_face_cascade = cv2.CascadeClassifier()\n",
    "        if not self.alt_face_cascade.load(cv2.samples.findFile(alt_face_cascade_name)):\n",
    "            print(\"--(!)Error loading alt face cascade\")\n",
    "            exit(0)\n",
    "\n",
    "        # create and load the alt2 face cascade\n",
    "        self.alt2_face_cascade = cv2.CascadeClassifier()\n",
    "        if not self.alt2_face_cascade.load(\n",
    "            cv2.samples.findFile(alt2_face_cascade_name)\n",
    "        ):\n",
    "            print(\"--(!)Error loading alt2 face cascade\")\n",
    "            exit(0)\n",
    "\n",
    "        # create and load the profile face cascade\n",
    "        self.profile_face_cascade = cv2.CascadeClassifier()\n",
    "        if not self.profile_face_cascade.load(\n",
    "            cv2.samples.findFile(profile_face_cascade_name)\n",
    "        ):\n",
    "            print(\"--(!)Error loading profile face cascade\")\n",
    "            exit(0)\n",
    "\n",
    "    def ultimate_find_face(self, frame):\n",
    "        face = self.find_frontal_face(frame)\n",
    "        if face is not None:\n",
    "            return face\n",
    "        face = self.find_alt_face(frame)\n",
    "        if face is not None:\n",
    "            return face\n",
    "        face = self.find_alt2_face(frame)\n",
    "        if face is not None:\n",
    "            return face\n",
    "        face = self.find_profile_face(frame)\n",
    "        return face\n",
    "\n",
    "    def find_frontal_face(self, frame):\n",
    "        # get the first face in the image\n",
    "        faces = self.frontal_face_cascade.detectMultiScale(frame)\n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        face = self.frontal_face_cascade.detectMultiScale(frame)[0]\n",
    "        x, y, width, height = face\n",
    "\n",
    "        # crop the picture so it only includes that face\n",
    "        face = frame[y : y + height, x : x + width]\n",
    "        return face\n",
    "\n",
    "    def find_alt_face(self, frame):\n",
    "        # get the first face in the image\n",
    "        faces = self.alt_face_cascade.detectMultiScale(frame)\n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        face = self.alt_face_cascade.detectMultiScale(frame)[0]\n",
    "        x, y, width, height = face\n",
    "\n",
    "        # crop the picture so it only includes that face\n",
    "        face = frame[y : y + height, x : x + width]\n",
    "        return face\n",
    "\n",
    "    def find_alt2_face(self, frame):\n",
    "        # get the first face in the image\n",
    "        faces = self.alt2_face_cascade.detectMultiScale(frame)\n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        face = self.alt2_face_cascade.detectMultiScale(frame)[0]\n",
    "        x, y, width, height = face\n",
    "\n",
    "        # crop the picture so it only includes that face\n",
    "        face = frame[y : y + height, x : x + width]\n",
    "        return face\n",
    "\n",
    "    def find_profile_face(self, frame):\n",
    "        # get the first face in the image\n",
    "        faces = self.profile_face_cascade.detectMultiScale(frame)\n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        face = self.profile_face_cascade.detectMultiScale(frame)[0]\n",
    "        x, y, width, height = face\n",
    "\n",
    "        # crop the picture so it only includes that face\n",
    "        face = frame[y : y + height, x : x + width]\n",
    "        return face\n",
    "\n",
    "    def detect_triplet(self, triplet):\n",
    "        center, left, right = triplet\n",
    "        center_face = self.ultimate_find_face(center)\n",
    "        left_face = self.ultimate_find_face(left)\n",
    "        right_face = self.ultimate_find_face(right)\n",
    "        return [\n",
    "            center_face,\n",
    "            left_face,\n",
    "            right_face,\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches(img1, img2):\n",
    "    my_SIFT_instance = cv2.SIFT_create()\n",
    "    kp1, des1 = my_SIFT_instance.detectAndCompute(img1, None)\n",
    "    kp2, des2 = my_SIFT_instance.detectAndCompute(img2, None)\n",
    "    lowes = cv2.FlannBasedMatcher().knnMatch(\n",
    "        np.asarray(des1, np.float32), np.asarray(des2, np.float32), k=2\n",
    "    )\n",
    "\n",
    "    leftPoints, rightPoints = [], []\n",
    "    for m, n in lowes:\n",
    "        if (m.distance / n.distance) < 0.8:\n",
    "            rightPoints.append(kp2[m.trainIdx].pt)\n",
    "            leftPoints.append(kp1[m.queryIdx].pt)\n",
    "\n",
    "    leftPoints, rightPoints = np.int32(leftPoints), np.int32(rightPoints)\n",
    "\n",
    "    return len(leftPoints)\n",
    "\n",
    "def get_triplet_match(triplet, show_imgs=False):\n",
    "    if show_imgs:\n",
    "        show_img(triplet, names=[\"C\", \"L\", \"R\"])\n",
    "\n",
    "    center, left, right = triplet\n",
    "    if center is None:\n",
    "        return matches(left, right)\n",
    "    if left is None:\n",
    "        return matches(center, right)\n",
    "    if right is None:\n",
    "        return matches(center, left)\n",
    "\n",
    "    sizes = [(img.shape[0] * img.shape[1], img) for img in triplet]\n",
    "    try:\n",
    "        sizes.remove(min(sizes))\n",
    "    except:\n",
    "        sizes = [sizes[0], sizes[1]]\n",
    "\n",
    "    return matches(sizes[0][1], sizes[1][1])\n",
    "\n",
    "def train(real_imgs, fake_imgs, face_finder):\n",
    "    real_faces = [face_finder.detect_triplet(triplet) for triplet in real_imgs]\n",
    "    fake_faces = [face_finder.detect_triplet(triplet) for triplet in fake_imgs]\n",
    "    \n",
    "    real_face_matches = [\n",
    "        get_triplet_match(real_face_triplet) for real_face_triplet in real_faces\n",
    "    ]\n",
    "    \n",
    "    fake_face_matches = [\n",
    "        get_triplet_match(fake_face_triplet) for fake_face_triplet in fake_faces\n",
    "    ]\n",
    "    match_threshold = (max(real_face_matches) + min(fake_face_matches)) // 2\n",
    "    \n",
    "    return match_threshold\n",
    "\n",
    "def detect(triplet, threshold):\n",
    "    matches = get_triplet_match(triplet, show_imgs=False)\n",
    "    if matches < threshold:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs, fake_imgs, test_imgs, real_label_count, fake_label_count, dataset_size = import_images(0.7)\n",
    "path = \"./res\"\n",
    "face_finder = FaceFinder(path)\n",
    "true_labels = [True for _ in range(real_label_count)]+[False for _ in range(fake_label_count)]\n",
    "\n",
    "train_start = time.time()\n",
    "match_threshold = train(real_imgs, fake_imgs, face_finder)\n",
    "train_end = time.time()\n",
    "test_start = time.time()\n",
    "test_faces = [face_finder.detect_triplet(triplet) for triplet in test_imgs]\n",
    "results = [detect(triplet, match_threshold) for triplet in test_faces]\n",
    "test_end = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "Dataset Size 72.00: \n",
      "Training 21.47 s: \n",
      "Testing 12.98 s: \n",
      "\n",
      "\n",
      "\tPositive\tNegative\n",
      "----------------------------------\n",
      "True\t\t4\t\t4\n",
      "False\t\t0\t\t0\n"
     ]
    }
   ],
   "source": [
    "true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if true_labels[i] == True and results[i] == True: true_pos += 1\n",
    "    elif true_labels[i] == False and results[i] == False: true_neg += 1\n",
    "    elif true_labels[i] == False and results[i] == True: false_pos += 1\n",
    "    elif true_labels[i] == True and results[i] == False: false_neg += 1\n",
    "\n",
    "precision = true_pos / (true_pos + false_pos) * 100\n",
    "recall = true_pos / (true_pos + false_neg) * 100\n",
    "\n",
    "print('Precision: %.2f%%' % precision)\n",
    "print('Recall: %.2f%%'% recall)\n",
    "print('Dataset Size: %.2f ' % dataset_size)\n",
    "print('Training: %.2f s ' % (train_end - train_start))\n",
    "print('Testing: %.2f s ' % (test_end - test_start))\n",
    "\n",
    "# print confusion matrix\n",
    "confusion_matrix = f\"\\n\\n\\tPositive\\tNegative\\n----------------------------------\\nTrue\\t\\t{true_pos}\\t\\t{true_neg}\\nFalse\\t\\t{false_pos}\\t\\t{false_neg}\"\n",
    "print(confusion_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
