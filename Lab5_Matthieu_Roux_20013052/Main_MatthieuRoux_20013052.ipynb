{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ELEC 474 Lab 5\n",
    "Matthieu Roux - 20013052\n",
    "\n",
    "## 0 Helpers and imports\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.shape_base import block\n",
    "from numpy.lib.shape_base import tile\n",
    "\n",
    "coaster_l_path = \"coaster_left.jpg\"\n",
    "coaster_r_path = \"coaster_right.jpg\"\n",
    "\n",
    "tape_l_path = \"tape_l.jpg\"\n",
    "tape_r_path = \"tape_r.jpg\"\n",
    "\n",
    "bike_l_path = \"bike_l.png\"\n",
    "bike_r_path = \"bike_r.png\"\n",
    "\n",
    "coaster_l_img = cv2.imread(coaster_l_path, 0)\n",
    "coaster_r_img = cv2.imread(coaster_r_path, 0)\n",
    "\n",
    "tape_l_img = cv2.imread(tape_l_path, 0)\n",
    "tape_r_img = cv2.imread(tape_r_path, 0)\n",
    "\n",
    "bike_l_img = cv2.imread(bike_l_path, 0)\n",
    "bike_r_img = cv2.imread(bike_r_path, 0)\n",
    "\n",
    "\n",
    "def resize_img(img, max_side=1000):\n",
    "    \"\"\"\n",
    "    This function resizes an image, while keeping its aspect ratio,\n",
    "    ensuring that its largest side is not greater\n",
    "    than max_side (1000px by default).\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    # if the image is small enough as is, return it unchanged\n",
    "    if height <= 1000 and width <= 1000:\n",
    "        return img\n",
    "    dim = tuple()\n",
    "    if height > width:\n",
    "        scale_ratio = max_side / height\n",
    "        dim = (int(width * scale_ratio), max_side)\n",
    "    else:\n",
    "        scale_ratio = max_side / width\n",
    "        dim = (max_side, int(height * scale_ratio))\n",
    "    return cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def show_img(imgs, names=[], use_plt=False):\n",
    "    # resize\n",
    "    for i in range(len(imgs)):\n",
    "        imgs[i] = resize_img(imgs[i], max_side=750)\n",
    "\n",
    "    # create windows\n",
    "    if len(names) == 0:\n",
    "        names = [str(i) for i in range(len(imgs))]\n",
    "    for name in names:\n",
    "        cv2.namedWindow(name)\n",
    "\n",
    "    while True:\n",
    "        # Wait a little bit for the image to re-draw\n",
    "        key = cv2.waitKey(5)\n",
    "        for img, name in zip(imgs, names):\n",
    "            cv2.imshow(name, img)\n",
    "\n",
    "        # If an x is pressed, the window will close\n",
    "        if key == ord(\"x\"):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## 1.1 Fundamental Matrix Calculation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lowe_ratio_match(matches, threshold_ratio=0.5):\n",
    "    lowe_matches = [m for m, n in matches if m.distance < threshold_ratio * n.distance]\n",
    "    return lowe_matches\n",
    "\n",
    "\n",
    "def compute_matches(des1, des2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    return bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "\n",
    "def get_matches(img_1, img_2):\n",
    "    my_SIFT_instance = cv2.SIFT_create()\n",
    "    # putting keypoints in variabels for better legibility\n",
    "    kp1, des1 = my_SIFT_instance.detectAndCompute(img_1, None)\n",
    "    kp2, des2 = my_SIFT_instance.detectAndCompute(img_2, None)\n",
    "\n",
    "    # # matching\n",
    "    # bf = cv2.BFMatcher()\n",
    "    # matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # get lowe matches\n",
    "    lowe_matches = lowe_ratio_match(matches, threshold_ratio=0.8)\n",
    "    # get the index of points in matches\n",
    "    matches_kp1 = np.int32([kp1[m.queryIdx].pt for m in lowe_matches])\n",
    "    matches_kp2 = np.int32([kp2[m.trainIdx].pt for m in lowe_matches])\n",
    "    return (\n",
    "        matches_kp1,\n",
    "        matches_kp2,\n",
    "        lowe_matches,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_fundamental_matrix(img1, img2):\n",
    "    # get the matches\n",
    "    pts_1, pts_2, _ = get_matches(img1, img2)\n",
    "\n",
    "    fundamental_matrix, mask = cv2.findFundamentalMat(\n",
    "        pts_1,\n",
    "        pts_2,\n",
    "        cv2.RANSAC,\n",
    "        10,\n",
    "    )\n",
    "    pts_1 = pts_1[mask.ravel() == 1]\n",
    "    pts_2 = pts_2[mask.ravel() == 1]\n",
    "    return fundamental_matrix, (pts_1, pts_2)"
   ]
  },
  {
   "source": [
    "## 1.2 Image Rectification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_image(img1, img2, fundamental_matrix, inlier_matches):\n",
    "    pts1, pts2 = inlier_matches\n",
    "    _, homography1, homography2 = cv2.stereoRectifyUncalibrated(\n",
    "        pts1, pts2, fundamental_matrix, (img1.shape[0], img1.shape[1]))\n",
    "    new_img1 = cv2.warpPerspective(img1, homography1, img1.shape)\n",
    "    new_img2 = cv2.warpPerspective(img1, homography2, img1.shape)\n",
    "    return new_img1, new_img2"
   ]
  },
  {
   "source": [
    "\n",
    "## 1.3 Block Matching Disparity Map Calculation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_disparity_img(img1, img2, numDisparities=16, blockSize=5):\n",
    "    stereo = cv2.StereoBM_create(\n",
    "        numDisparities=numDisparities,\n",
    "        blockSize=blockSize,\n",
    "    )\n",
    "    img1 = cv2.GaussianBlur(src=img1, ksize=(0, 0), sigmaX=4)\n",
    "    img2 = cv2.GaussianBlur(src=img2, ksize=(0, 0), sigmaX=4)\n",
    "    disparity = stereo.compute(img1, img2)\n",
    "    min = disparity.min()\n",
    "    max = disparity.max()\n",
    "    disparity = np.uint8(255 * (disparity - min) / (max - min))\n",
    "    disparity = resize_img(disparity, max_side=500)\n",
    "    return disparity"
   ]
  },
  {
   "source": [
    "## 2 Execution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike Matrix\n",
    "\n",
    "# get the matrix\n",
    "f, inlier_matches = get_fundamental_matrix(bike_l_img, bike_r_img)\n",
    "# rectify image\n",
    "img1, img2 = rectify_image(bike_l_img, bike_r_img, f, inlier_matches)\n",
    "# displayed rectified image\n",
    "show_img(imgs=[img1, img2], names=[\"Left bike\", \"Right bike\"])\n",
    "# get disaprity\n",
    "bike_disparity = get_disparity_img(\n",
    "    img1,\n",
    "    img2,\n",
    "    numDisparities=16,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Coaster\n",
    "# get the matrix\n",
    "f, inlier_matches = get_fundamental_matrix(coaster_l_img, coaster_r_img)\n",
    "# rectify image\n",
    "img1, img2 = rectify_image(coaster_l_img, coaster_r_img, f, inlier_matches)\n",
    "# displayed rectified image\n",
    "show_img(imgs=[img1, img2], names=[\"Left Coaster\", \"Right Coaster\"])\n",
    "# get disaprity\n",
    "coaster_disparity = get_disparity_img(\n",
    "    img1,\n",
    "    img2,\n",
    "    numDisparities=16,\n",
    "    blockSize=13,\n",
    ")\n",
    "\n",
    "# Tape Matrix\n",
    "\n",
    "# get the matrix\n",
    "f, inlier_matches = get_fundamental_matrix(tape_l_img, tape_r_img)\n",
    "# rectify image\n",
    "img1, img2 = rectify_image(tape_l_img, tape_r_img, f, inlier_matches)\n",
    "# displayed rectified image\n",
    "show_img(imgs=[img1, img2], names=[\"Left Tape\", \"Right Tape\"])\n",
    "# get disaprity\n",
    "tape_disparity = get_disparity_img(\n",
    "    img1,\n",
    "    img2,\n",
    "    numDisparities=16,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "\n",
    "# display diparity images\n",
    "show_img(\n",
    "    imgs=[coaster_disparity, tape_disparity, bike_disparity],\n",
    "    names=[\"Coaster Disparity\", \"Tape Disparity\",\"Bike Disparity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}